{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "def01a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import calendar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8844c123",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Company ID               Company Name  Establishment Date  \\\n",
      "0           0                  Acme Inc.       1577750400000   \n",
      "1           1                 Best Corp.       1616284800000   \n",
      "2           2  Bright Future Enterprises       1605312000000   \n",
      "3           3                 Delta Inc.       1604620800000   \n",
      "4           4           Echo Enterprises       1651708800000   \n",
      "\n",
      "   Number of Employees  \n",
      "0                  404  \n",
      "1                  229  \n",
      "2                  222  \n",
      "3                  662  \n",
      "4                  255  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 10 entries, 0 to 9\n",
      "Data columns (total 4 columns):\n",
      " #   Column               Non-Null Count  Dtype \n",
      "---  ------               --------------  ----- \n",
      " 0   Company ID           10 non-null     int64 \n",
      " 1   Company Name         10 non-null     object\n",
      " 2   Establishment Date   10 non-null     int64 \n",
      " 3   Number of Employees  10 non-null     int64 \n",
      "dtypes: int64(3), object(1)\n",
      "memory usage: 400.0+ bytes\n",
      "None\n",
      "            posted_at  id      state    zip   price  company_id\n",
      "0 2022-04-13 11:43:00   1    expired  10506  119.34           4\n",
      "1 2021-01-20 04:54:00   2  cancelled  10506  197.89           5\n",
      "2 2021-07-21 15:29:00   3    expired  35786  335.85           8\n",
      "3 2021-06-13 20:11:00   4    expired  78956  150.00           6\n",
      "4 2022-06-23 06:52:00   5    expired  78956  158.09           8\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 102 entries, 0 to 101\n",
      "Data columns (total 6 columns):\n",
      " #   Column      Non-Null Count  Dtype         \n",
      "---  ------      --------------  -----         \n",
      " 0   posted_at   102 non-null    datetime64[ns]\n",
      " 1   id          102 non-null    int64         \n",
      " 2   state       102 non-null    object        \n",
      " 3   zip         102 non-null    int64         \n",
      " 4   price       100 non-null    float64       \n",
      " 5   company_id  102 non-null    int64         \n",
      "dtypes: datetime64[ns](1), float64(1), int64(3), object(1)\n",
      "memory usage: 4.9+ KB\n",
      "None\n",
      "   zip_code        location\n",
      "0     10506  King's Landing\n",
      "1     80976           Dorne\n",
      "2     78956         Braavos\n",
      "3     67305       Harrenhal\n",
      "4     25089      Winterfell\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8 entries, 0 to 7\n",
      "Data columns (total 2 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   zip_code  8 non-null      int64 \n",
      " 1   location  8 non-null      object\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 260.0+ bytes\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Load companies.json, jobs.json and locations.csv into DataFrames\n",
    "companies_data = pd.read_json('data/companies.json')\n",
    "jobs_data = pd.read_json('data/jobs.json')\n",
    "locations_data = pd.read_csv('data/locations.csv')\n",
    "\n",
    "#Let's have a look at the data in these data frames:\n",
    "print(companies_data.head())\n",
    "print(companies_data.info())\n",
    "print(jobs_data.head())\n",
    "print(jobs_data.info())\n",
    "print(locations_data.head())\n",
    "print(locations_data.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "712713f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Establishment Date has been converted to a regular timestamp.\n",
      "\n",
      "['cancelled', 'expired', 'posted', 'osted', 'canceled']\n",
      "['expired' 'canceled' 'posted']\n",
      "The state column in jobs_data has been corrected.\n",
      "\n",
      "Total rows with null zip in jobs dataframe: 0\n",
      "\n",
      "Checking duplicated rows for jobs_data...\n",
      "Duplicates found:\n",
      "              posted_at  id     state    zip   price  company_id\n",
      "2   2021-07-21 15:29:00   3   expired  35786  335.85           8\n",
      "96  2022-12-29 16:05:00  97  canceled  78956   11.83           1\n",
      "100 2022-12-29 16:05:00  97  canceled  78956   11.83           1\n",
      "101 2021-07-21 15:29:00   3   expired  35786  335.85           8\n",
      "\n",
      "Checking duplicated rows for locations_data...\n",
      "No duplicates found.\n",
      "\n",
      "Checking duplicated rows for companies_data...\n",
      "No duplicates found.\n",
      "\n",
      "Duplicated rows have been dropped in the dataframe jobs_data.\n"
     ]
    }
   ],
   "source": [
    "# ********************************* Data quality checks *********************************\n",
    "\n",
    "# The Establishment Date is originally a Unix timestamp, and so let's convert it to a regular timestamp\n",
    "companies_data['Establishment Date'] = pd.to_datetime(companies_data['Establishment Date'], unit='ms', origin='unix')\n",
    "print(\"Establishment Date has been converted to a regular timestamp.\\n\")\n",
    "\n",
    "# Let's make sure that the values of the \"state\" column are all correct\n",
    "distinct_states = jobs_data['state'].value_counts().index.tolist()\n",
    "print(distinct_states)\n",
    "\n",
    "# Some of th state values seem to be wrong, so let's correct them:\n",
    "jobs_data['state'] = jobs_data['state'].replace({'cancelled': 'canceled', 'osted': 'posted'})\n",
    "\n",
    "# Let's check the changes\n",
    "print(jobs_data['state'].unique())\n",
    "print(\"The state column in jobs_data has been corrected.\\n\")\n",
    "\n",
    "# Let's also check for rows where the \"zip_code\" column is null\n",
    "null_zip_code_rows = jobs_data['zip'].isnull().sum()\n",
    "print(\"Total rows with null zip in jobs dataframe:\", null_zip_code_rows)\n",
    "\n",
    "#Let's define a funtion to check if there are any duplicated rows\n",
    "def check_duplicates(dataframe):\n",
    "    # Check for duplicates and return the duplicated rows if any are found\n",
    "    duplicates = dataframe[dataframe.duplicated(keep=False)]\n",
    "    if not duplicates.empty:\n",
    "        print(\"Duplicates found:\")\n",
    "        print(duplicates)\n",
    "    else:\n",
    "        print(\"No duplicates found.\")\n",
    "    \n",
    "#Now let's use this funtion to detecte duplicated rows:\n",
    "print(\"\\nChecking duplicated rows for jobs_data...\")\n",
    "check_duplicates(jobs_data)\n",
    "\n",
    "print(\"\\nChecking duplicated rows for locations_data...\")\n",
    "check_duplicates(locations_data)\n",
    "\n",
    "print(\"\\nChecking duplicated rows for companies_data...\")\n",
    "check_duplicates(companies_data)\n",
    "\n",
    "#Duplicated rows have been found in jobs_data, and so let's drop the duplicated rows:\n",
    "jobs_data = jobs_data.drop_duplicates(keep='first')\n",
    "print(\"\\nDuplicated rows have been dropped in the dataframe jobs_data.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f09929a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Location with the most jobs (posted or expired):\n",
      "Location     Tarth\n",
      "Job Count       15\n",
      "Name: 0, dtype: object\n"
     ]
    }
   ],
   "source": [
    "#1. What location has the most jobs that are either posted or expired?\n",
    "# Join the \"jobs\" and \"locations\" DataFrames based on the condition zip=zip_code\n",
    "joined_data = jobs_data.merge(locations_data, left_on='zip', right_on='zip_code', how='inner')\n",
    "#print(joined_data)\n",
    "\n",
    "# Filter for jobs that are either \"posted\" or \"expired\"\n",
    "joined_data = joined_data[joined_data['state'].isin(['posted', 'expired'])]\n",
    "#print(joined_data)\n",
    "\n",
    "# Group by location and count the number of jobs in each location\n",
    "location_job_counts = joined_data['location'].value_counts().reset_index()\n",
    "location_job_counts.columns = ['Location', 'Job Count']\n",
    "\n",
    "# Find the location with the highest job count\n",
    "max_job_location = location_job_counts.loc[location_job_counts['Job Count'].idxmax()]\n",
    "\n",
    "print(\"Location with the most jobs (posted or expired):\")\n",
    "print(max_job_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "791ae676",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Month with the most canceled jobs: June\n"
     ]
    }
   ],
   "source": [
    "#2. What month had the most cancelled jobs? (Just the month without the year)\n",
    "\n",
    "jobs_data['posted_at_month'] = jobs_data['posted_at'].dt.month\n",
    "canceled_jobs = jobs_data[jobs_data['state'] == 'canceled']\n",
    "\n",
    "# Group by month and count canceled jobs\n",
    "canceled_jobs_by_month = canceled_jobs.groupby('posted_at_month')['state'].count()\n",
    "\n",
    "# Get the month with the highest count\n",
    "most_canceled_month = canceled_jobs_by_month.idxmax()\n",
    "\n",
    "print(\"Month with the most canceled jobs:\", calendar.month_name[most_canceled_month])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "731ca3a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Month and year with the most canceled jobs: (6, 2021)\n"
     ]
    }
   ],
   "source": [
    "#2. What month had the most cancelled jobs? (Month and year)\n",
    "jobs_data['posted_at_month'] = jobs_data['posted_at'].dt.month\n",
    "jobs_data['posted_at_year'] = jobs_data['posted_at'].dt.year\n",
    "canceled_jobs = jobs_data[jobs_data['state'] == 'canceled']\n",
    "\n",
    "# Group by month and count canceled jobs\n",
    "canceled_jobs_by_month_year = canceled_jobs.groupby(['posted_at_month', 'posted_at_year'])['state'].count()\n",
    "\n",
    "# Get the month with the highest count\n",
    "most_canceled_month_year = canceled_jobs_by_month_year.idxmax()\n",
    "\n",
    "print(\"Month and year with the most canceled jobs:\", most_canceled_month_year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4820f214",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Company with the highest ratio:\n",
      "Company Name: Best Corp.\n",
      "Ratio: 0.017467248908296942\n"
     ]
    }
   ],
   "source": [
    "#3. Which company has the highest ratio of posted jobs to employee count?\n",
    "\n",
    "# We already know the employee count from the data provided, let's count the jobs count per company\n",
    "posted_jobs = jobs_data[jobs_data['state'] == 'posted']\n",
    "posted_jobs = posted_jobs.groupby('company_id').size().reset_index(name='jobs_count')\n",
    "posted_jobs.set_index('company_id', inplace=True)\n",
    "\n",
    "posted_jobs_employee = posted_jobs.merge(companies_data, left_on='company_id', right_on='Company ID', how='inner')\n",
    "posted_jobs_employee['ratio_posted_jobs_employee'] = posted_jobs_employee['jobs_count'] / posted_jobs_employee['Number of Employees']\n",
    "\n",
    "sorted_posted_jobs_employee = posted_jobs_employee.sort_values(by='ratio_posted_jobs_employee', ascending=False)\n",
    "\n",
    "# Get the company with the highest ratio\n",
    "highest_ratio_company = sorted_posted_jobs_employee.iloc[0]\n",
    "\n",
    "# Print the company name and the highest ratio\n",
    "print(\"Company with the highest ratio:\")\n",
    "print(\"Company Name:\", highest_ratio_company['Company Name'])\n",
    "print(\"Ratio:\", highest_ratio_company['ratio_posted_jobs_employee'])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
